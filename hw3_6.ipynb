{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#  下载数据 ",
   "id": "dc76f3f3c2e938b9"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "!gdown --id '1awF7pZ9Dz7X1jn1_QAiKN-_v56veCEKy' --output food-11.zip\n",
    "\n",
    "# Unzip the dataset.\n",
    "!unzip -q food-11.zip\n"
   ],
   "id": "bd4f38da3c728136"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# 导入包",
   "id": "c4e1c32f586d904b"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.models as models\n",
    "from torchvision import transforms\n",
    "import numpy as np\n",
    "import sys\n",
    "import os\n",
    "import random\n",
    "from PIL import Image\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn.functional as F\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import torch.optim as optim\n",
    "from torchvision.datasets import DatasetFolder\n"
   ],
   "id": "9b6fca9aea9a65f0"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# 构建ResNet-18-512模型",
   "id": "fb14bf750a975dd6"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 基础残差块",
   "id": "31328017e34cf704"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "class BasicBlock(nn.Module):\n",
    "    expansion = 1\n",
    "\n",
    "    def __init__(self, in_channels, out_channels, stride=1, downsample=None):\n",
    "        super(BasicBlock, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3,\n",
    "                               stride=stride, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3,\n",
    "                               stride=1, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
    "        self.downsample = downsample\n",
    "        self.stride = stride\n",
    "\n",
    "    def forward(self, x):\n",
    "        identity = x\n",
    "\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "\n",
    "        if self.downsample is not None:\n",
    "            identity = self.downsample(x)\n",
    "\n",
    "        out += identity\n",
    "        out = self.relu(out)\n",
    "\n",
    "        return out\n"
   ],
   "id": "ebb8c8db3e4dad6"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 适配512×512的ResNet-18模型",
   "id": "70a7787d719efd34"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "class ResNet18_512(nn.Module):\n",
    "    def __init__(self, block, layers, num_classes=11, num_channels=3, dropout_rate=0.5):\n",
    "        super(ResNet18_512, self).__init__()\n",
    "        self.in_channels = 64\n",
    "        self.dropout_rate = dropout_rate\n",
    "\n",
    "        # 初始卷积层 - 针对512×512调整\n",
    "        self.conv1 = nn.Conv2d(num_channels, 64, kernel_size=7, stride=2,\n",
    "                               padding=3, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "\n",
    "        # 残差层\n",
    "        self.layer1 = self._make_layer(block, 64, layers[0])\n",
    "        self.layer2 = self._make_layer(block, 128, layers[1], stride=2)\n",
    "        self.layer3 = self._make_layer(block, 256, layers[2], stride=2)\n",
    "        self.layer4 = self._make_layer(block, 512, layers[3], stride=2)\n",
    "\n",
    "        # 分类器\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.dropout = nn.Dropout(dropout_rate)\n",
    "        self.fc = nn.Linear(512 * block.expansion, num_classes)\n",
    "\n",
    "        # 权重初始化\n",
    "        self._initialize_weights()\n",
    "\n",
    "    def _make_layer(self, block, out_channels, blocks, stride=1):\n",
    "        downsample = None\n",
    "        if stride != 1 or self.in_channels != out_channels * block.expansion:\n",
    "            downsample = nn.Sequential(\n",
    "                nn.Conv2d(self.in_channels, out_channels * block.expansion,\n",
    "                          kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(out_channels * block.expansion),\n",
    "            )\n",
    "\n",
    "        layers = []\n",
    "        layers.append(block(self.in_channels, out_channels, stride, downsample))\n",
    "        self.in_channels = out_channels * block.expansion\n",
    "        for _ in range(1, blocks):\n",
    "            layers.append(block(self.in_channels, out_channels))\n",
    "\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def _initialize_weights(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                nn.init.constant_(m.weight, 1)\n",
    "                nn.init.constant_(m.bin_channels, 0)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # 输入: 512×512\n",
    "        x = self.conv1(x)    # 512→256\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.maxpool(x)  # 256→128\n",
    "\n",
    "        x = self.layer1(x)   # 128→128\n",
    "        x = self.layer2(x)   # 128→64\n",
    "        x = self.layer3(x)   # 64→32\n",
    "        x = self.layer4(x)   # 32→16\n",
    "\n",
    "        x = self.avgpool(x)  # 16→1\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc(x)\n",
    "\n",
    "        return x"
   ],
   "id": "fc3c31e07085977e"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 创建模型的函数",
   "id": "374ddeaa5ecf436a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def resnet18_512(num_classes=11):\n",
    "    \"\"\"创建适配512×512的ResNet-18模型\"\"\"\n",
    "    return ResNet18_512(BasicBlock, [2, 2, 2, 2], num_classes=num_classes)"
   ],
   "id": "a2ea50c6053e4ba8"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# 添加工具函数",
   "id": "b33472660dc0905b"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 绘制训练和损失曲线",
   "id": "f32d1df708bd61c7"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def plot_loss_curves(train_losses, val_losses, save_path=None):\n",
    "    \"\"\"绘制训练和验证损失曲线\"\"\"\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(train_losses, label='训练损失', linewidth=2)\n",
    "    plt.plot(val_losses, label='验证损失', linewidth=2)\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.title('训练和验证损失曲线')\n",
    "    plt.legend()\n",
    "    plt.grid(True, alpha=0.3)\n",
    "\n",
    "    if save_path:\n",
    "        plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
    "        print(f\"图片已保存到: {save_path}\")"
   ],
   "id": "44ebd96cbe790760"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 绘制训练准确率曲线",
   "id": "4415aab72b3fbd42"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def plot_accuracy_curves(train_accuracies, val_accuracies, save_path=None):\n",
    "    \"\"\"绘制准确率曲线\"\"\"\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    epochs = range(1, len(train_accuracies) + 1)\n",
    "\n",
    "    plt.plot(epochs, train_accuracies, 'b-', label='训练准确率', linewidth=2)\n",
    "    plt.plot(epochs, val_accuracies, 'r-', label='验证准确率', linewidth=2)\n",
    "\n",
    "    plt.title('训练和验证准确率', fontsize=14, fontweight='bold')\n",
    "    plt.xlabel('Epochs', fontsize=12)\n",
    "    plt.ylabel('Accuracy (%)', fontsize=12)\n",
    "    plt.legend(fontsize=12)\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.ylim(bottom=0)\n",
    "\n",
    "    # 添加最佳准确率标注\n",
    "    best_val_acc = max(val_accuracies)\n",
    "    best_epoch = val_accuracies.index(best_val_acc) + 1\n",
    "    plt.axvline(x=best_epoch, color='gray', linestyle='--', alpha=0.7)\n",
    "    plt.text(best_epoch, best_val_acc / 2, f'最佳: {best_val_acc:.2f}%\\nEpoch: {best_epoch}',\n",
    "             ha='center', va='center', fontsize=10, \n",
    "             bbox=dict(boxstyle=\"round,pad=0.3\", facecolor=\"white\", alpha=0.8))\n",
    "\n",
    "    plt.tight_layout()\n",
    "\n",
    "    if save_path:\n",
    "        plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
    "        plt.close()\n",
    "    else:\n",
    "        plt.show()"
   ],
   "id": "c3372b0c90b696a3"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 绘制综合曲线",
   "id": "71e3c0c5472ce2d3"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def plot_training_curves(train_losses, val_losses, train_accuracies, val_accuracies, save_path=None):\n",
    "    \"\"\"绘制综合训练曲线\"\"\"\n",
    "    fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(12, 10))\n",
    "    epochs = range(1, len(train_losses) + 1)\n",
    "\n",
    "    # 绘制损失曲线\n",
    "    ax1.plot(epochs, train_losses, 'b-', label='训练损失', linewidth=2)\n",
    "    ax1.plot(epochs, val_losses, 'r-', label='验证损失', linewidth=2)\n",
    "    ax1.set_title('训练和验证损失', fontsize=14, fontweight='bold')\n",
    "    ax1.set_ylabel('Loss', fontsize=12)\n",
    "    ax1.legend(fontsize=12)\n",
    "    ax1.grid(True, alpha=0.3)\n",
    "\n",
    "    # 绘制准确率曲线\n",
    "    ax2.plot(epochs, train_accuracies, 'b-', label='训练准确率', linewidth=2)\n",
    "    ax2.plot(epochs, val_accuracies, 'r-', label='验证准确率', linewidth=2)\n",
    "    ax2.set_title('训练和验证准确率', fontsize=14, fontweight='bold')\n",
    "    ax2.set_xlabel('Epochs', fontsize=12)\n",
    "    ax2.set_ylabel('Accuracy (%)', fontsize=12)\n",
    "    ax2.legend(fontsize=12)\n",
    "    ax2.grid(True, alpha=0.3)\n",
    "    ax2.set_ylim(bottom=0)\n",
    "\n",
    "    # 添加最佳准确率标注\n",
    "    best_val_acc = max(val_accuracies)\n",
    "    best_epoch = val_accuracies.index(best_val_acc) + 1\n",
    "    ax2.axvline(x=best_epoch, color='gray', linestyle='--', alpha=0.7)\n",
    "    ax2.text(best_epoch, best_val_acc / 2, f'最佳: {best_val_acc:.2f}%',\n",
    "             ha='center', va='center', fontsize=10,\n",
    "             bbox=dict(boxstyle=\"round,pad=0.3\", facecolor=\"white\", alpha=0.8))\n",
    "\n",
    "    plt.tight_layout()\n",
    "\n",
    "    if save_path:\n",
    "        plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
    "        plt.close()\n",
    "    else:\n",
    "        plt.show()\n"
   ],
   "id": "59d4e469b937e880"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# 半监督学习训练器",
   "id": "386a41089f142d88"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 图片加载器",
   "id": "3ee04f54fbb7d397"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# 定义可序列化的图片加载函数\n",
    "def pil_loader(path):\n",
    "    \"\"\"使用PIL加载图片，支持多种格式\"\"\"\n",
    "    with open(path, 'rb') as f:\n",
    "        img = Image.open(f)\n",
    "        return img.convert('RGB')"
   ],
   "id": "55a988b8cd67ac16"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 训练器主体类",
   "id": "1f6d70487303289f"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "class SemiSupervisedTrainer:\n",
    "    \"\"\"优化版半监督训练器\"\"\"\n",
    "    \n",
    "    def __init__(self, model, train_loader, unlabeled_loader, valid_loader,\n",
    "                 optimizer, criterion, device, pseudo_threshold=0.9, consistency_weight=0.3):\n",
    "        self.model = model\n",
    "        self.train_loader = train_loader\n",
    "        self.unlabeled_loader = unlabeled_loader\n",
    "        self.valid_loader = valid_loader\n",
    "        self.optimizer = optimizer\n",
    "        self.criterion = criterion\n",
    "        self.device = device\n",
    "        self.pseudo_threshold = pseudo_threshold\n",
    "        self.consistency_weight = consistency_weight\n",
    "\n",
    "        # 数据增强\n",
    "        self.weak_augment = transforms.Compose([\n",
    "            transforms.RandomHorizontalFlip(p=0.5),\n",
    "            transforms.RandomRotation(degrees=10),\n",
    "            transforms.ColorJitter(brightness=0.2, contrast=0.2),\n",
    "        ])\n",
    "\n",
    "        self.strong_augment = transforms.Compose([\n",
    "            transforms.RandomHorizontalFlip(p=0.5),\n",
    "            transforms.RandomRotation(degrees=15),\n",
    "            transforms.ColorJitter(brightness=0.3, contrast=0.3, saturation=0.3),\n",
    "            transforms.RandomAffine(degrees=0, translate=(0.1, 0.1), scale=(0.9, 1.1)),\n",
    "            transforms.GaussianBlur(kernel_size=3, sigma=(0.1, 2.0)),\n",
    "        ])\n",
    "        \n",
    "        # 训练历史记录\n",
    "        self.pseudo_label_stats = []\n",
    "\n",
    "    def generate_pseudo_labels(self, epoch=None):\n",
    "        \"\"\"优化版伪标签生成：动态阈值调整\"\"\"\n",
    "        # 动态调整阈值：前期严格，后期放宽\n",
    "        if epoch < 20:\n",
    "            confidence_threshold = self.pseudo_threshold + 0.03  # 更严格\n",
    "        elif epoch < 50:\n",
    "            confidence_threshold = self.pseudo_threshold + 0.01\n",
    "        else:\n",
    "            confidence_threshold = self.pseudo_threshold - 0.02  # 稍宽松\n",
    "\n",
    "        self.model.eval()\n",
    "        pseudo_data = []\n",
    "        pseudo_labels = []\n",
    "        pseudo_confidences = []\n",
    "        total_samples = 0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for data, _ in self.unlabeled_loader:\n",
    "                data = data.to(self.device)\n",
    "                outputs = self.model(data)\n",
    "                probabilities = F.softmax(outputs, dim=1)\n",
    "                max_probs, predictions = torch.max(probabilities, 1)\n",
    "                \n",
    "                total_samples += data.size(0)\n",
    "                \n",
    "                # 筛选高置信度样本\n",
    "                mask = max_probs > confidence_threshold\n",
    "                high_conf_data = data[mask].cpu()\n",
    "                high_conf_preds = predictions[mask].cpu()\n",
    "                high_conf_probs = max_probs[mask].cpu()\n",
    "                \n",
    "                if len(high_conf_data) > 0:\n",
    "                    for i in range(len(high_conf_data)):\n",
    "                        pseudo_data.append(high_conf_data[i])\n",
    "                        pseudo_labels.append(high_conf_preds[i])\n",
    "                        pseudo_confidences.append(high_conf_probs[i].item())\n",
    "\n",
    "        # 统计信息\n",
    "        selection_rate = len(pseudo_data) / total_samples if total_samples > 0 else 0\n",
    "        avg_confidence = np.mean(pseudo_confidences) if pseudo_confidences else 0\n",
    "        \n",
    "        print(f\"Epoch {epoch}: 生成了 {len(pseudo_data)}/{total_samples} 个伪标签 \"\n",
    "              f\"(选择率: {selection_rate:.3f}, 阈值: {confidence_threshold:.3f}, \"\n",
    "              f\"平均置信度: {avg_confidence:.4f})\")\n",
    "        \n",
    "        # 记录统计信息\n",
    "        self.pseudo_label_stats.append({\n",
    "            'epoch': epoch,\n",
    "            'count': len(pseudo_data),\n",
    "            'selection_rate': selection_rate,\n",
    "            'avg_confidence': avg_confidence,\n",
    "            'threshold': confidence_threshold\n",
    "        })\n",
    "        \n",
    "        return pseudo_data, pseudo_labels\n",
    "\n",
    "    def get_dynamic_consistency_weight(self, epoch):\n",
    "        \"\"\"动态调整一致性权重\"\"\"\n",
    "        if epoch < 10:\n",
    "            return self.consistency_weight * 0.3  # 前期注重有监督学习\n",
    "        elif epoch < 30:\n",
    "            return self.consistency_weight * 0.7\n",
    "        elif epoch < 60:\n",
    "            return self.consistency_weight\n",
    "        else:\n",
    "            return self.consistency_weight * 1.2  # 后期增加无监督学习\n",
    "\n",
    "    def consistency_loss(self, unlabeled_batch):\n",
    "        \"\"\"计算一致性损失\"\"\"\n",
    "        batch_size = unlabeled_batch.size(0)\n",
    "\n",
    "        # 弱增强\n",
    "        weak_aug = self.weak_augment(unlabeled_batch)\n",
    "        # 强增强\n",
    "        strong_aug = self.strong_augment(unlabeled_batch)\n",
    "\n",
    "        # 获取预测\n",
    "        with torch.no_grad():\n",
    "            weak_output = F.softmax(self.model(weak_aug), dim=1)\n",
    "\n",
    "        strong_output = F.log_softmax(self.model(strong_aug), dim=1)\n",
    "\n",
    "        # 计算KL散度损失\n",
    "        consistency_loss = F.kl_div(strong_output, weak_output, reduction='batchmean')\n",
    "        return consistency_loss\n",
    "\n",
    "    def calculate_topk_accuracy(self, outputs, targets, k=5):\n",
    "        \"\"\"计算top-k准确率\"\"\"\n",
    "        _, topk_pred = outputs.topk(k, 1, True, True)\n",
    "        topk_correct = topk_pred.eq(targets.view(-1, 1).expand_as(topk_pred))\n",
    "        return topk_correct.any(1).sum().item()\n",
    "\n",
    "    def train_epoch(self, epoch, use_consistency=True, use_pseudo_labels=False):\n",
    "        \"\"\"优化版训练epoch\"\"\"\n",
    "        self.model.train()\n",
    "        train_loss = 0.0\n",
    "        train_correct = 0\n",
    "        train_top5_correct = 0\n",
    "        train_total = 0\n",
    "        \n",
    "        # 动态权重\n",
    "        current_consistency_weight = self.get_dynamic_consistency_weight(epoch) if use_consistency else 0.0\n",
    "        \n",
    "        # 改进的伪标签策略\n",
    "        pseudo_dataset = None\n",
    "        if use_pseudo_labels and epoch % 5 == 0 and epoch >= 10:\n",
    "            pseudo_data, pseudo_labels = self.generate_pseudo_labels(epoch=epoch)\n",
    "            if pseudo_data and len(pseudo_data) > 50:  # 只有足够多的伪标签时才使用\n",
    "                pseudo_dataset = list(zip(pseudo_data, pseudo_labels))\n",
    "                print(f\"使用 {len(pseudo_data)} 个伪标签样本扩展训练集\")\n",
    "            else:\n",
    "                print(\"伪标签样本不足，跳过使用\")\n",
    "\n",
    "        # 创建无标签数据迭代器\n",
    "        unlabeled_iter = iter(self.unlabeled_loader)\n",
    "\n",
    "        for batch_idx, (data, target) in enumerate(self.train_loader):\n",
    "            data, target = data.to(self.device), target.to(self.device)\n",
    "\n",
    "            self.optimizer.zero_grad()\n",
    "\n",
    "            # 有监督损失\n",
    "            output = self.model(data)\n",
    "            supervised_loss = self.criterion(output, target)\n",
    "\n",
    "            total_loss = supervised_loss\n",
    "\n",
    "            # 无监督损失（一致性正则化）\n",
    "            consistency_loss = torch.tensor(0.0)\n",
    "            if use_consistency and current_consistency_weight > 0:\n",
    "                try:\n",
    "                    unlabeled_data, _ = next(unlabeled_iter)\n",
    "                    unlabeled_data = unlabeled_data.to(self.device)\n",
    "                    consistency_loss = self.consistency_loss(unlabeled_data)\n",
    "                    total_loss = supervised_loss + current_consistency_weight * consistency_loss\n",
    "                except StopIteration:\n",
    "                    unlabeled_iter = iter(self.unlabeled_loader)\n",
    "\n",
    "            total_loss.backward()\n",
    "            self.optimizer.step()\n",
    "\n",
    "            train_loss += total_loss.item()\n",
    "\n",
    "            # 计算准确率\n",
    "            _, predicted = torch.max(output.data, 1)\n",
    "            train_total += target.size(0)\n",
    "            train_correct += (predicted == target).sum().item()\n",
    "            train_top5_correct += self.calculate_topk_accuracy(output, target, k=5)\n",
    "\n",
    "            # 定期打印训练信息\n",
    "            if batch_idx % 50 == 0:\n",
    "                cons_loss_val = consistency_loss.item() if use_consistency else 0.0\n",
    "                print(f'Epoch: {epoch} | Batch: {batch_idx}/{len(self.train_loader)} | '\n",
    "                      f'总损失: {total_loss.item():.4f} | 有监督: {supervised_loss.item():.4f} | '\n",
    "                      f'一致性: {cons_loss_val:.4f} | 权重: {current_consistency_weight:.4f}')\n",
    "\n",
    "        # 计算平均训练损失和准确率\n",
    "        avg_train_loss = train_loss / len(self.train_loader)\n",
    "        train_accuracy = 100.0 * train_correct / train_total\n",
    "        train_top5_accuracy = 100.0 * train_top5_correct / train_total\n",
    "\n",
    "        return avg_train_loss, train_accuracy, train_top5_accuracy\n",
    "\n",
    "    def validate(self):\n",
    "        \"\"\"验证模型性能\"\"\"\n",
    "        self.model.eval()\n",
    "        val_loss = 0.0\n",
    "        val_correct = 0\n",
    "        val_top5_correct = 0\n",
    "        val_total = 0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for data, target in self.valid_loader:\n",
    "                data, target = data.to(self.device), target.to(self.device)\n",
    "\n",
    "                output = self.model(data)\n",
    "                loss = self.criterion(output, target)\n",
    "\n",
    "                val_loss += loss.item()\n",
    "                _, predicted = torch.max(output.data, 1)\n",
    "                val_total += target.size(0)\n",
    "                val_correct += (predicted == target).sum().item()\n",
    "                val_top5_correct += self.calculate_topk_accuracy(output, target, k=5)\n",
    "\n",
    "        avg_val_loss = val_loss / len(self.valid_loader)\n",
    "        val_accuracy = 100.0 * val_correct / val_total\n",
    "        val_top5_accuracy = 100.0 * val_top5_correct / val_total\n",
    "\n",
    "        return avg_val_loss, val_accuracy, val_top5_accuracy\n"
   ],
   "id": "32d9264e55063250"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# 训练配置",
   "id": "d0709a72944d7b18"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# 基本参数\n",
    "BASE_DIR = os.getcwd() \n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"使用设备: {device}\")\n",
    "\n",
    "# 创建结果目录\n",
    "now_time = datetime.now()\n",
    "time_str = datetime.strftime(now_time, '%m-%d_%H-%M')\n",
    "log_dir = os.path.join(BASE_DIR, \"results\", time_str)\n",
    "if not os.path.exists(log_dir):\n",
    "    os.makedirs(log_dir)\n",
    "print(f\"结果保存目录: {log_dir}\")\n",
    "\n",
    "# 超参数（优化版）\n",
    "MAX_EPOCH = 200\n",
    "BATCH_SIZE = 32\n",
    "LR = 0.001\n",
    "PATIENCE = 25  # 增加耐心值\n",
    "\n",
    "# 半监督参数优化\n",
    "PSEUDO_THRESHOLD = 0.90  # 稍微降低阈值\n",
    "CONSISTENCY_WEIGHT = 0.2  # 增加一致性权重\n",
    "\n",
    "print(\"训练配置完成\")"
   ],
   "id": "5bbf480bd97e53ed"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# 数据加载",
   "id": "d0da8ae0321bb312"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 数据增强",
   "id": "1337792d02b152ee"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# 数据增强\n",
    "train_tfm = transforms.Compose([\n",
    "    transforms.Resize((512, 512)),\n",
    "    transforms.RandomHorizontalFlip(p=0.5),\n",
    "    transforms.RandomRotation(degrees=15),\n",
    "    transforms.ColorJitter(brightness=0.3, contrast=0.3, saturation=0.3),\n",
    "    transforms.RandomAffine(degrees=0, translate=(0.1, 0.1), scale=(0.9, 1.1)),\n",
    "    transforms.RandomCrop(512, padding=16),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "test_tfm = transforms.Compose([\n",
    "    transforms.Resize((512, 512)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])"
   ],
   "id": "faedd3f32064e9f"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 加载数据",
   "id": "8afcd406e8dd582b"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# 加载数据集\n",
    "train_set = DatasetFolder(\n",
    "    os.path.join(BASE_DIR, \"food-11\", \"training\", \"labeled\"),\n",
    "    loader=pil_loader,\n",
    "    extensions=\"jpg\",\n",
    "    transform=train_tfm\n",
    ")\n",
    "\n",
    "valid_set = DatasetFolder(\n",
    "    os.path.join(BASE_DIR, \"food-11\", \"validation\"),\n",
    "    loader=pil_loader,\n",
    "    extensions=\"jpg\",\n",
    "    transform=test_tfm\n",
    ")\n",
    "\n",
    "unlabeled_set = DatasetFolder(\n",
    "    os.path.join(BASE_DIR, \"food-11\", \"training\", \"unlabeled\"),\n",
    "    loader=pil_loader,\n",
    "    extensions=\"jpg\",\n",
    "    transform=train_tfm\n",
    ")\n",
    "print(f\"训练集: {len(train_set)}\")\n",
    "print(f\"无标签集: {len(unlabeled_set)}\")\n",
    "print(f\"验证集: {len(valid_set)}\")"
   ],
   "id": "fd981c7043bce71a"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 数据加载器",
   "id": "e19b4a6abe4b057e"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# 数据加载器\n",
    "num_workers = 2 if os.name == 'nt' else 4\n",
    "pin_memory = (device.type == 'cuda')\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    train_set,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True,\n",
    "    num_workers=num_workers,\n",
    "    pin_memory=pin_memory\n",
    ")\n",
    "\n",
    "unlabeled_loader = DataLoader(\n",
    "    unlabeled_set,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True,\n",
    "    num_workers=num_workers,\n",
    "    pin_memory=pin_memory\n",
    ")\n",
    "\n",
    "valid_loader = DataLoader(\n",
    "    valid_set,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=False,\n",
    "    num_workers=num_workers,\n",
    "    pin_memory=pin_memory\n",
    ")\n",
    "\n",
    "print(\"数据加载完成\")"
   ],
   "id": "27f572e2ae18c664"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# 模型初始化",
   "id": "a79aa1f47051ddc4"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "model = resnet18_512(num_classes=11)\n",
    "model.to(device)"
   ],
   "id": "fe19fc5d4940eb65"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "175051a8c5db3d6c"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# 损失函数和优化器",
   "id": "e3fc39439f3be836"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.AdamW(model.parameters(), lr=LR, weight_decay=0.01)\n",
    "\n",
    "# 使用CosineAnnealingWarmRestarts学习率调度器\n",
    "scheduler = optim.lr_scheduler.CosineAnnealingWarmRestarts(\n",
    "    optimizer, T_0=50, T_mult=2, eta_min=1e-6\n",
    ")\n",
    "\n",
    "print(f\"模型初始化完成，参数量: {sum(p.numel() for p in model.parameters()):,}\")"
   ],
   "id": "2d833c466d04f20a"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# 创建训练器",
   "id": "e8556aa82884dffc"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "trainer = SemiSupervisedTrainer(\n",
    "    model=model,\n",
    "    train_loader=train_loader,\n",
    "    unlabeled_loader=unlabeled_loader,\n",
    "    valid_loader=valid_loader,\n",
    "    optimizer=optimizer,\n",
    "    criterion=criterion,\n",
    "    device=device,\n",
    "    pseudo_threshold=PSEUDO_THRESHOLD,\n",
    "    consistency_weight=CONSISTENCY_WEIGHT\n",
    ")\n",
    "\n",
    "print(\"训练器创建完成\")"
   ],
   "id": "1a013e679e053563"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# 开始训练",
   "id": "d4ea06be07df024e"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 初始化记录变量",
   "id": "445fc2ccd096f401"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "train_losses = []\n",
    "val_losses = []\n",
    "train_accuracies = []\n",
    "val_accuracies = []\n",
    "train_top5_accuracies = []\n",
    "val_top5_accuracies = []\n",
    "learning_rates = []\n",
    "best_val_accuracy = 0.0\n",
    "early_stop_counter = 0\n",
    "best_epoch = 0"
   ],
   "id": "59d0c195c30ce31e"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 正式开始训练",
   "id": "a26788dd8198a762"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "print(\"开始半监督训练...\")\n",
    "\n",
    "for epoch in range(MAX_EPOCH):\n",
    "    # 训练阶段\n",
    "    train_loss, train_accuracy, train_top5_accuracy = trainer.train_epoch(\n",
    "        epoch,\n",
    "        use_consistency=True,\n",
    "        use_pseudo_labels=True\n",
    "    )\n",
    "\n",
    "    train_losses.append(train_loss)\n",
    "    train_accuracies.append(train_accuracy)\n",
    "    train_top5_accuracies.append(train_top5_accuracy)\n",
    "\n",
    "    # 更新学习率并记录\n",
    "    current_lr = scheduler.get_last_lr()[0]\n",
    "    learning_rates.append(current_lr)\n",
    "    scheduler.step()\n",
    "\n",
    "    # 验证阶段\n",
    "    val_loss, val_accuracy, val_top5_accuracy = trainer.validate()\n",
    "    val_losses.append(val_loss)\n",
    "    val_accuracies.append(val_accuracy)\n",
    "    val_top5_accuracies.append(val_top5_accuracy)\n",
    "\n",
    "    # 早停判断和模型保存\n",
    "    if val_accuracy > best_val_accuracy:\n",
    "        best_val_accuracy = val_accuracy\n",
    "        best_epoch = epoch\n",
    "        early_stop_counter = 0\n",
    "\n",
    "        # 保存最佳模型\n",
    "        checkpoint = {\n",
    "            \"model_state_dict\": model.state_dict(),\n",
    "            \"optimizer_state_dict\": optimizer.state_dict(),\n",
    "            \"scheduler_state_dict\": scheduler.state_dict(),\n",
    "            \"epoch\": epoch,\n",
    "            \"best_val_accuracy\": best_val_accuracy,\n",
    "            \"val_loss\": val_loss,\n",
    "            \"train_accuracy\": train_accuracy,\n",
    "            \"train_loss\": train_loss\n",
    "        }\n",
    "        path_checkpoint = os.path.join(log_dir, \"checkpoint_best.pkl\")\n",
    "        torch.save(checkpoint, path_checkpoint)\n",
    "        print(f\"✅ 保存最佳模型，验证准确率: {best_val_accuracy:.2f}%\")\n",
    "    \n",
    "    # 保存接近最佳的模型（用于集成）\n",
    "    elif val_accuracy > best_val_accuracy - 2.0:\n",
    "        checkpoint = {\n",
    "            \"model_state_dict\": model.state_dict(),\n",
    "            \"val_accuracy\": val_accuracy,\n",
    "            \"epoch\": epoch\n",
    "        }\n",
    "        torch.save(checkpoint, os.path.join(log_dir, f\"checkpoint_epoch_{epoch}_acc_{val_accuracy:.2f}.pth\"))\n",
    "\n",
    "    else:\n",
    "        early_stop_counter += 1\n",
    "\n",
    "    # 打印训练信息\n",
    "    print(f'Epoch: {epoch:03d}/{MAX_EPOCH}, '\n",
    "          f'训练损失: {train_loss:.4f}, 训练准确率: {train_accuracy:.2f}% (Top-5: {train_top5_accuracy:.2f}%), '\n",
    "          f'验证损失: {val_loss:.4f}, 验证准确率: {val_accuracy:.2f}% (Top-5: {val_top5_accuracy:.2f}%), '\n",
    "          f'学习率: {current_lr:.6f}, '\n",
    "          f'最佳: {best_val_accuracy:.2f}% @ Epoch {best_epoch}, '\n",
    "          f'早停计数: {early_stop_counter}/{PATIENCE}')\n",
    "    print('-' * 80)\n",
    "\n",
    "    # 早停检查\n",
    "    if early_stop_counter >= PATIENCE:\n",
    "        print(f\"🚨 早停触发！在 epoch {epoch} 停止训练\")\n",
    "        print(f\"🏆 最佳模型在 epoch {best_epoch}, 验证准确率: {best_val_accuracy:.2f}%\")\n",
    "        break\n",
    "\n",
    "# 训练完成\n",
    "print(f\"训练完成！最终最佳验证准确率: {best_val_accuracy:.2f}%\")"
   ],
   "id": "fe8f0bf5329b53fc"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# 保存训练记录",
   "id": "36820c82c2c6e217"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "training_history = {\n",
    "    'train_losses': train_losses,\n",
    "    'val_losses': val_losses,\n",
    "    'train_accuracies': train_accuracies,\n",
    "    'val_accuracies': val_accuracies,\n",
    "    'train_top5_accuracies': train_top5_accuracies,\n",
    "    'val_top5_accuracies': val_top5_accuracies,\n",
    "    'learning_rates': learning_rates,\n",
    "    'best_val_accuracy': best_val_accuracy,\n",
    "    'best_epoch': best_epoch,\n",
    "    'pseudo_label_stats': trainer.pseudo_label_stats\n",
    "}\n",
    "\n",
    "torch.save(training_history, os.path.join(log_dir, 'training_history.pth'))\n",
    "\n",
    "# 绘制训练曲线\n",
    "picture_path_loss = os.path.join(log_dir, 'loss_curves.png')\n",
    "picture_path_acc = os.path.join(log_dir, 'accuracy_curves.png')\n",
    "picture_path_combined = os.path.join(log_dir, 'training_curves.png')\n",
    "\n",
    "plot_loss_curves(train_losses, val_losses, picture_path_loss)\n",
    "plot_accuracy_curves(train_accuracies, val_accuracies, picture_path_acc)\n",
    "plot_training_curves(train_losses, val_losses, train_accuracies, val_accuracies, picture_path_combined)\n",
    "\n",
    "print(f\"训练曲线已保存至: {log_dir}\")"
   ],
   "id": "9b16ee94b2634f3a"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# 伪标签统计",
   "id": "9ca5cf73a1fd218d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "if trainer.pseudo_label_stats:\n",
    "    pseudo_df = pd.DataFrame(trainer.pseudo_label_stats)\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    \n",
    "    plt.subplot(2, 2, 1)\n",
    "    plt.plot(pseudo_df['epoch'], pseudo_df['count'], 'b-o')\n",
    "    plt.title('伪标签数量变化')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('数量')\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.subplot(2, 2, 2)\n",
    "    plt.plot(pseudo_df['epoch'], pseudo_df['selection_rate'], 'g-o')\n",
    "    plt.title('伪标签选择率')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('选择率')\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.subplot(2, 2, 3)\n",
    "    plt.plot(pseudo_df['epoch'], pseudo_df['avg_confidence'], 'r-o')\n",
    "    plt.title('伪标签平均置信度')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('置信度')\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.subplot(2, 2, 4)\n",
    "    plt.plot(pseudo_df['epoch'], pseudo_df['threshold'], 'purple-o')\n",
    "    plt.title('动态阈值变化')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('阈值')\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(log_dir, 'pseudo_label_stats.png'), dpi=300, bbox_inches='tight')\n",
    "    plt.show()"
   ],
   "id": "caab9f9eea5a1828"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# 最终结果统计",
   "id": "3df257c9293fcec8"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "print(\"=\" * 80)\n",
    "print(\"训练总结:\")\n",
    "print(f\"最佳验证准确率: {best_val_accuracy:.2f}% (Epoch {best_epoch})\")\n",
    "print(f\"最终训练准确率: {train_accuracies[-1]:.2f}%\")\n",
    "print(f\"最终验证准确率: {val_accuracies[-1]:.2f}%\")\n",
    "print(f\"训练轮数: {len(train_accuracies)}\")\n",
    "print(f\"结果保存目录: {log_dir}\")\n",
    "print(\"=\" * 80)"
   ],
   "id": "52b1e8985cacb07"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
