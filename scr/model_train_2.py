import os
from datetime import datetime
import numpy as np
import torch.nn as nn
import torch
from torch.utils.data import DataLoader
from torchvision.datasets import DatasetFolder
import torch.optim as optim
from tools.hw3_model import resnet18,FoodCNN
from tools.hw3_common_tools import plot_loss_curves, plot_accuracy_curves, plot_training_curves
from PIL import Image
import torchvision.transforms as transforms

#è‡ªåˆ¶æ¨¡å‹ AdamW

# å®šä¹‰å¯åºåˆ—åŒ–çš„å›¾ç‰‡åŠ è½½å‡½æ•°
def pil_loader(path):
    """ä½¿ç”¨PILåŠ è½½å›¾ç‰‡ï¼Œæ”¯æŒå¤šç§æ ¼å¼"""
    # æ‰“å¼€å›¾ç‰‡å¹¶è½¬æ¢ä¸ºRGBï¼ˆå¤„ç†é€æ˜åº¦é€šé“ï¼‰
    with open(path, 'rb') as f:
        img = Image.open(f)
        return img.convert('RGB')


# è®¾ç½®åŸºç¡€è·¯å¾„å’Œè®¾å¤‡
BASE_DIR = os.path.dirname(os.path.abspath(__file__))
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
pin_memory = (device.type == 'cuda')

# åœ¨Windowsä¸Šï¼Œå¤šè¿›ç¨‹éœ€è¦æ”¾åœ¨mainä¿æŠ¤ä¸­
if __name__ == "__main__":
    # ============================ é…ç½®å‚æ•° ============================
    parent_dir = os.path.dirname(BASE_DIR)  # è·å–ä¸Šçº§æ–‡ä»¶å¤¹
    # åˆ›å»ºæ—¥å¿—ç›®å½•
    now_time = datetime.now()
    time_str = datetime.strftime(now_time, '%m-%d_%H-%M')
    log_dir = os.path.join(BASE_DIR, "..", "results", time_str)
    if not os.path.exists(log_dir):
        os.makedirs(log_dir)

    # è®­ç»ƒè¶…å‚æ•°
    MAX_EPOCH = 182  # æ€»è®­ç»ƒè½®æ•°ï¼ŒåŸºäº64000æ¬¡è¿­ä»£è®¡ç®—å¾—å‡º
    BATCH_SIZE = 128  # æ‰¹å¤§å°
    LR = 0.1
    log_interval = 1
    PATIENCE = 20
    milestones = [92, 136]  # å­¦ä¹ ç‡è°ƒæ•´çš„é‡Œç¨‹ç¢‘epochï¼ˆåœ¨32kå’Œ48kè¿­ä»£æ—¶å­¦ä¹ ç‡é™¤ä»¥10ï¼‰è¿™æ˜¯è®ºæ–‡è¯´çš„ï¼Œè®¡ç®—å¾—åˆ°92,136


    # ============================ step 1/5 æ•°æ®åŠ è½½ ============================
    train_tfm = transforms.Compose([
        transforms.Resize((128, 128)),
        transforms.RandomHorizontalFlip(p=0.5),
        transforms.RandomRotation(degrees=15),
        transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),
        transforms.RandomAffine(degrees=0, translate=(0.1, 0.1), scale=(0.9, 1.1)),
        transforms.ToTensor(),
        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
    ])

    test_tfm = transforms.Compose([
        transforms.Resize((128, 128)),
        transforms.ToTensor(),
        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
    ])

    # ä½¿ç”¨æ™®é€šå‡½æ•°æ›¿ä»£lambdaå‡½æ•°
    train_set = DatasetFolder(
        parent_dir+"/food-11/training/labeled",
        loader=pil_loader,
        extensions="jpg",
        transform=train_tfm
    )
    valid_set = DatasetFolder(
        "../food-11/validation",
        loader=pil_loader,
        extensions="jpg",
        transform=test_tfm
    )
    unlabeled_set = DatasetFolder(
        "../food-11/training/unlabeled",
        loader=pil_loader,
        extensions="jpg",
        transform=train_tfm
    )
    test_set = DatasetFolder(
        "../food-11/testing",
        loader=pil_loader,
        extensions="jpg",
        transform=test_tfm
    )

    # åœ¨Windowsä¸Šï¼Œå¯ä»¥é€‚å½“å‡å°‘num_workersæˆ–è®¾ä¸º0
    num_workers = 2 if os.name == 'nt' else 2  # Windowsè®¾ä¸º0ï¼ŒLinux/Macè®¾ä¸º2

    train_loader = DataLoader(
        train_set,
        batch_size=BATCH_SIZE,
        shuffle=True,
        num_workers=num_workers,
        pin_memory=pin_memory
    )
    valid_loader = DataLoader(
        valid_set,
        batch_size=BATCH_SIZE,
        shuffle=False,
        num_workers=num_workers,
        pin_memory=pin_memory
    )
    test_loader = DataLoader(
        test_set,
        batch_size=BATCH_SIZE,
        shuffle=False,
        num_workers=0,  # æµ‹è¯•é›†é€šå¸¸ä¸éœ€è¦å¤šè¿›ç¨‹
        pin_memory=pin_memory
    )

    print(f"è®­ç»ƒé›†: {len(train_set)}")
    print(f"éªŒè¯é›†: {len(valid_set)}")
    print(f"ä½¿ç”¨è®¾å¤‡: {device}")
    print(f"æ•°æ®åŠ è½½è¿›ç¨‹æ•°: {num_workers}")

    # ============================ step 2/5 æ¨¡å‹å®šä¹‰ ============================
    model = FoodCNN(num_classes=11)
    model.to(device)

    # æ‰“å°æ¨¡å‹ä¿¡æ¯
    print(f"æ¨¡å‹å·²åˆ›å»ºï¼Œç§»åŠ¨åˆ°è®¾å¤‡: {device}")
    print(f"æ¨¡å‹å‚æ•°é‡: {sum(p.numel() for p in model.parameters()):,}")



    # ============================ step 3/5 æŸå¤±å‡½æ•° ============================
    criterion = nn.CrossEntropyLoss()  # åˆ†ç±»ä»»åŠ¡ç”¨äº¤å‰ç†µæŸå¤±

    # ============================ step 4/5 ä¼˜åŒ–å™¨ ============================
    optimizer = optim.AdamW(model.parameters(), lr=0.001, weight_decay=0.01)
    scheduler = optim.lr_scheduler.MultiStepLR(optimizer, gamma=0.1, milestones=milestones)

    # ============================ step 5/5 è®­ç»ƒå¾ªç¯ ============================
    # è®°å½•è®­ç»ƒè¿‡ç¨‹ä¸­çš„å„é¡¹æŒ‡æ ‡
    train_losses = []
    val_losses = []
    train_accuracies = []
    val_accuracies = []
    learning_rates = []
    best_val_accuracy = 0.0
    early_stop_counter = 0
    best_epoch = 0

    print("å¼€å§‹è®­ç»ƒ...")
    for epoch in range(MAX_EPOCH):
        # ===== è®­ç»ƒé˜¶æ®µ =====
        model.train()
        train_loss = 0.0
        train_correct = 0
        train_total = 0

        for batch_idx, (data, target) in enumerate(train_loader):
            data, target = data.to(device), target.to(device)

            # ç¡®ä¿æ ‡ç­¾æ˜¯longç±»å‹ï¼ˆCrossEntropyLossè¦æ±‚ï¼‰
            if target.dtype != torch.long:
                target = target.long()

            optimizer.zero_grad()
            output = model(data)
            loss = criterion(output, target)
            loss.backward()
            optimizer.step()

            train_loss += loss.item()

            # è®¡ç®—è®­ç»ƒå‡†ç¡®ç‡
            _, predicted = torch.max(output.data, 1)
            train_total += target.size(0)
            train_correct += (predicted == target).sum().item()

        avg_train_loss = train_loss / len(train_loader)
        train_accuracy = 100.0 * train_correct / train_total
        train_losses.append(avg_train_loss)
        train_accuracies.append(train_accuracy)

        # æ›´æ–°å­¦ä¹ ç‡å¹¶è®°å½•
        current_lr = scheduler.get_last_lr()[0]
        learning_rates.append(current_lr)
        scheduler.step()

        # ===== éªŒè¯é˜¶æ®µ =====
        model.eval()
        val_loss = 0.0
        val_correct = 0
        val_total = 0

        with torch.no_grad():
            for data, target in valid_loader:
                data, target = data.to(device), target.to(device)

                # ç¡®ä¿æ ‡ç­¾æ˜¯longç±»å‹
                if target.dtype != torch.long:
                    target = target.long()

                output = model(data)
                loss = criterion(output, target)
                val_loss += loss.item()

                # è®¡ç®—éªŒè¯å‡†ç¡®ç‡
                _, predicted = torch.max(output.data, 1)
                val_total += target.size(0)
                val_correct += (predicted == target).sum().item()

        avg_val_loss = val_loss / len(valid_loader)
        val_accuracy = 100.0 * val_correct / val_total
        val_losses.append(avg_val_loss)
        val_accuracies.append(val_accuracy)

        # ===== æ—©åœåˆ¤æ–­å’Œæ¨¡å‹ä¿å­˜ =====
        if val_accuracy > best_val_accuracy:
            best_val_accuracy = val_accuracy
            best_epoch = epoch
            early_stop_counter = 0

            # ä¿å­˜æœ€ä½³æ¨¡å‹
            checkpoint = {
                "model_state_dict": model.state_dict(),
                "optimizer_state_dict": optimizer.state_dict(),
                "scheduler_state_dict": scheduler.state_dict(),
                "epoch": epoch,
                "best_val_accuracy": best_val_accuracy,
                "val_loss": avg_val_loss,
                "train_accuracy": train_accuracy,
                "train_loss": avg_train_loss
            }
            path_checkpoint = os.path.join(log_dir, "checkpoint_best.pkl")
            torch.save(checkpoint, path_checkpoint)
            print(f"âœ… ä¿å­˜æœ€ä½³æ¨¡å‹ï¼ŒéªŒè¯å‡†ç¡®ç‡: {best_val_accuracy:.2f}%")
        else:
            early_stop_counter += 1

        # æ‰“å°è®­ç»ƒå’ŒéªŒè¯ä¿¡æ¯
        if epoch % log_interval == 0:
            print(f'Epoch: {epoch:03d}/{MAX_EPOCH}, '
                  f'Train Loss: {avg_train_loss:.4f}, Train Acc: {train_accuracy:.2f}%, '
                  f'Val Loss: {avg_val_loss:.4f}, Val Acc: {val_accuracy:.2f}%, '
                  f'LR: {current_lr:.6f}, '
                  f'EarlyStop: {early_stop_counter}/{PATIENCE}')

        # æ—©åœæ£€æŸ¥
        if early_stop_counter >= PATIENCE:
            print(f"ğŸš¨ æ—©åœè§¦å‘ï¼åœ¨ epoch {epoch} åœæ­¢è®­ç»ƒ")
            print(f"ğŸ† æœ€ä½³æ¨¡å‹åœ¨ epoch {best_epoch}, éªŒè¯å‡†ç¡®ç‡: {best_val_accuracy:.2f}%")
            break

    # ===== è®­ç»ƒç»“æŸ =====
    now_time = datetime.now()
    time_str = datetime.strftime(now_time, '%m-%d_%H-%M')
    print(f"è®­ç»ƒå®Œæˆæ—¶é—´: {time_str}")
    print(f"æœ€ç»ˆæœ€ä½³éªŒè¯å‡†ç¡®ç‡: {best_val_accuracy:.2f}%")

    # ä¿å­˜è®­ç»ƒè®°å½•
    training_history = {
        'train_losses': train_losses,
        'val_losses': val_losses,
        'train_accuracies': train_accuracies,
        'val_accuracies': val_accuracies,
        'learning_rates': learning_rates,
        'best_val_accuracy': best_val_accuracy,
        'best_epoch': best_epoch
    }
    torch.save(training_history, os.path.join(log_dir, 'training_history.pth'))

    # ç»˜åˆ¶å„ç§æ›²çº¿
    picture_path_loss = os.path.join(log_dir, 'loss_curves.png')
    picture_path_acc = os.path.join(log_dir, 'accuracy_curves.png')
    picture_path_combined = os.path.join(log_dir, 'training_curves.png')

    plot_loss_curves(train_losses, val_losses, picture_path_loss)
    plot_accuracy_curves(train_accuracies, val_accuracies, picture_path_acc)
    plot_training_curves(train_losses, val_losses, train_accuracies, val_accuracies, picture_path_combined)

    print(f"æŸå¤±æ›²çº¿å·²ä¿å­˜è‡³: {picture_path_loss}")
    print(f"å‡†ç¡®ç‡æ›²çº¿å·²ä¿å­˜è‡³: {picture_path_acc}")
    print(f"ç»¼åˆè®­ç»ƒæ›²çº¿å·²ä¿å­˜è‡³: {picture_path_combined}")